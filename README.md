
<div id="outputFigDisplay" class="fig">
    <pre id="taag_output_text" style="left;" class="flag" contenteditable="true">
    <code>
    __  ___      _               _ ___    ____                             
   /  |/  /___ _(_)      _____  (_)   |  /  _/    _________  ____ ___      
  / /|_/ / __ `/ / | /| / / _ \/ / /| |  / /_____/ ___/ __ \/ __ `__ \     
 / /  / / /_/ / /| |/ |/ /  __/ / ___ |_/ /_____/ /__/ /_/ / / / / / /     
/_/  /_/\__,_/_/ |__/|__/\___/_/_/  |_/___/     \___/\____/_/ /_/ /_/      
    </code>
    </pre>
</div>

## Maiwei AI Lab - 迈微AI研习社

<a href="https://www.github.com/Charmve" target="_blank"><img src="https://img.shields.io/badge/作者-@Charmve-000000.svg?style=flat-square&logo=GitHub"></a>  [![CircleCI](https://circleci.com/gh/facebookresearch/pytorch3d.svg?style=svg)](https://circleci.com/gh/Charmve/computer-vision-in-action)

作者系迈微AI研习社创始人、CSDN博客专家，主要分享机器学习算法、计算机视觉等相关内容，每周研读顶会论文，持续关注前沿技术动态。底部有菜单分类，关注我们，一起学习成长。

---
<table align="center">
<tr>
<td>
<code>全面</code>&nbsp;<code>前沿</code>&nbsp;<code>免费</code>
<h1> 计算机视觉实战演练：算法与应用 <sup> 📌</sup>
<br><em>Computer Vision in Action</em></h1>

作者：张伟（Charmve）

<p align="center">
<a href="https://github.com/Charmve"><img src="https://img.shields.io/badge/👓-Charmve-blue&logo=GitHub" alt="GitHub"></a>
<a href="https://github.com/Charmve/computer-vision-in-action"><img src="https://img.shields.io/badge/CV-Action-yellow" alt="CV-Action"></a>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-lightgrey" /></a>
<a href="https://github.com/Charmve/computer-vision-in-action/edit/master/README.md"><img src="https://img.shields.io/github/stars/Charmve/computer-vision-in-action?style=social" alt="Stars"></a>
<a href="https://github.com/Charmve/computer-vision-in-action/edit/master/README.md"><img src="https://img.shields.io/github/forks/Charmve/computer-vision-in-action?style=social" alt="Forks"></a>
</p>

<div align="center">
	<img src="https://github.com/Charmve/computer-vision-in-action/blob/main/res/maiwei.png" width="240px" alt="logo:maiwei">
</div>

<h5>有疑问，跑起来就会变成一朵花 ❀ </5>

<br>

> <h4>在线阅读（内容实时更新）</h4>
> - 地址：https://charmve.github.io/computer-vision-in-action

> <h4>最新版PDF下载</h4>
> - 地址：https://github.com/charmve/computer-vision-in-action/releases

### 目录
- <b><h4>绪论篇</h4></b>
  - 第 0 章  [计算机视觉概述](https://charmve.github.io/computer-vision-in-action/#/chapter0/chapter0)
    - 1. 概述
    - 2. 计算机视觉基本概念
    - 3. 典型的计算机视觉任务
        - 图像分类 
        - 目标识别与目标检测
        - 实例分割与语义分割
        - 3D 建模
    - 4. [发展历史回顾](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/0_绪论/4_发展历史回顾.md)
    - 5. 小练习
    - 参考文献
- <b><h4>理论篇</h4></b>
  - 第 1 章 [神经网络](https://charmve.github.io/computer-vision-in-action/#/chapter2/chapter2)
    - 1.1 Softmax 回归
    - 1.2 反向传播算法
    - 1.3 多层感知器
    - 1.4 神经学观点
    - 1.5 [实战项目 1 - 手写字分类](https://blog.csdn.net/Charmve/article/details/108531735)
    - 参考文献
  - 第 2 章 [卷积神经网络](https://charmve.github.io/computer-vision-in-action/#/chapter3/chapter3)
    - 2.1 概述
    - 2.2 卷积和池化
    - 2.3 损失函数和优化
    - 2.4 线性分类Ⅱ
    - 2.5 进阶模型表示与图像特征
    - 2.6 优化，随机梯度下降
    - 2.7 [实战项目 2 - 动手搭建一个卷积神经网络](https://blog.csdn.net/Charmve/article/details/106076844)
    - 参考文献
  - 第 3 章 [图像分类](https://charmve.github.io/computer-vision-in-action/#/chapter1/chapter1)
    - 3.1 数据驱动方法
    - 3.2 k 最近邻算法
    - 3.3 线性分类
    - 3.4 逻辑回归 LR 
    - 3.5 [实战项目 3 - 表情识别]()
    - 参考文献
  - 第 4 章 [递归神经网络](https://charmve.github.io/computer-vision-in-action/#/chapter4/chapter4)
    - 4.1 递归神经网络 RNN
    - 4.2 循环神经网络的从零开始实现
    - 4.3 循环神经网络的简洁实现
    - 4.4 长短期记忆人工神经网络 LSTM
    - 4.5 门控循环单元（GRU）
    - 参考文献
  - 第 5 章 [模型拟合与优化算法]()
    - 5.1 优化与深度学习
    - 5.2 梯度下降和随机梯度下降
    - 5.3 小批量随机梯度下降
    - 5.4 动量法
    - 5.5 AdaGrad算法
    - 5.6 RMSProp算法
    - 5.7 AdaDelta算法
    - 5.8 Adam算法
    - 参考文献
- <b><h4>实战篇</h4></b>
  - 第 6 章 [深度学习环境搭建](https://charmve.github.io/computer-vision-in-action/#/chapter1/chapter1)
    - 6.1 PyTorch
    - 6.2 OpenCV
    - 6.3 Numpy
    - 6.4 Pandas
    - 参考文献
  - 第 7 章 [经典卷积神经网络架构：原理与PyTorch实现](https://charmve.github.io/computer-vision-in-action/#/chapter5/chapter5)
    - 7.1 [卷积神经网络（LeNet）](./docs/2_实战篇/chapter2_经典卷积神经网络架构-原理与PyTorch实现/chapter2_1-卷积神经网络（LeNet）.md)
    - 7.2 [深度卷积神经网络（AlexNet）](./docs/2_实战篇/chapter2_经典卷积神经网络架构-原理与PyTorch实现/chapter2_2-深度卷积神经网络（AlexNet）.md)
    - 7.3 使用重复元素的网络（VGG）
    - 7.4 含并行连结的网络（GoogLeNet）
    - 7.5 残差网络（ResNet）
    - 7.6 二阶网络编码解码（U-Net）
    - 7.7 实例分割网络（SegNet）
    - 7.8 Mask-RCNN
    - 7.9 [区域卷积神经网络（R-CNN）](./docs/2_实战篇/chapter2_经典卷积神经网络架构-原理与PyTorch实现/chapter2_9-区域卷积神经网络（R-CNN）.md)
    - 7.10 全卷积网络（FCN）
    - 7.11 [实战Kaggle比赛：图像分类（CIFAR-10）]()
    - 7.12 [实战Kaggle比赛：狗的品种识别（ImageNet Dogs）]()
    - 参考文献
  - 第 8 章 [著名数据集及基准](https://charmve.github.io/computer-vision-in-action/#/chapter6/chapter6)
    - 8.1 数据集
        - ImageNet
        - [MNIST](http://yann.lecun.com/exdb/mnist/)
        - COCO
        - CIFAR-10
    - 8.2 基准
    - 参考文献
  - 第 9 章 [检测与分割实战项目](https://charmve.github.io/computer-vision-in-action/#/chapter6/chapter6)
    - 9.1 语义分割
      - 9.1.1 [语义分割 PyTorch 版](https://github.com/Charmve/Semantic-Segmentation-PyTorch)
      - 9.1.2 实战项目 6
    - 9.2 目标检测
      - 9.2.1 常用网络
      - 9.2.2 实战项目 7
    - 9.3 实例分割 
      - 9.3.1 常用网络 
      - 9.3.2 实战项目 8
      - 9.3.3 新方法：滑动窗口, PointRend, PolarMask
    - 参考文献
  - 第 10 章 [图像分类项目实战](https://charmve.github.io/computer-vision-in-action/#/chapter6/chapter6)
    - 10.1 [手写字识别](https://blog.csdn.net/Charmve/article/details/108531735)
    - 10.2 [文本检测](https://github.com/Charmve/Scene-Text-Detection)
    - 10.3 [车道线检测](https://github.com/Charmve/Awesome-Lane-Detection)
      - 10.3.1 常用网络 
      - 10.3.2 实战项目 9
    - 10.4 [镜面检测](https://github.com/Charmve/Mirror-Glass-Detection)
    - 10.5 [图像抠图 Matting](https://github.com/Charmve/TimeWarp)
    - 参考文献
- <b><h4>进阶篇</h4></b>
  - 第 11 章 [可视化和理解](https://charmve.github.io/computer-vision-in-action/#/chapter5/chapter5)
    - 11.1 表征可视化
    - 11.2 对抗实例
    - 11.3 DeepDream 和风格迁移
    - 11.4 实战项目 10
    - 参考文献
  - 第 12 章 [生成对抗模型](https://charmve.github.io/computer-vision-in-action/#/chapter6/chapter6)
    - 12.1 Pixel RNN/CNN
    - 12.2 自编码器 Auto-encoder
    - 12.3 生成对抗网络 GAN
      - 12.3.1 原理
      - 12.3.2 项目实战
        - [StyleGAN](https://github.com/Charmve/VOGUE-Try-On)
        - [StyleGAN 2.0](https://blog.csdn.net/Charmve/article/details/115315353)
    - 12.4 [变分自编码器 Variational Auto-encoder, VAE](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter12-生成对抗模型/chapter12_4-变分自编码器VAE.md)
      - [12.4.1 概述](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter12-生成对抗模型/chapter12_4-变分自编码器VAE.md#1241-概述)    
      - [12.4.2 基本原理](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter12-生成对抗模型/chapter12_4-变分自编码器VAE.md#1242-基本原理)        
        - [12.4.2.1 定义](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter12-生成对抗模型/chapter12_4-变分自编码器VAE.md#1-定义)        
        - [12.4.2.2 理论基础：三要素](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter12-生成对抗模型/chapter12_4-变分自编码器VAE.md#2-理论基础三要素) 
        - [12.4.2.3 推导过程](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter12-生成对抗模型/chapter12_4-变分自编码器VAE.md#3-推导过程)            
      - [12.4.3 VAE v.s. AE 区别与联系](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter12-生成对抗模型/chapter12_4-变分自编码器VAE.md#1243-vae-vs-ae-区别与联系)    
      - [12.4.4 变分自编码器的代码实现](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter12-生成对抗模型/chapter12_4-变分自编码器VAE.md#1244-变分自编码器的代码实现)    
      - [12.4.5 卷积变分自编码器的实现与简单应用](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter12-生成对抗模型/chapter12_4-变分自编码器VAE.md#1245-卷积变分自编码器的实现与简单应用)             
      - [参考文献](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter12-生成对抗模型/chapter12_4-变分自编码器VAE.md#参考文献) 
    - 参考文献
  - 第 13 章 [深度增强学习](https://charmve.github.io/computer-vision-in-action/#/chapter6/chapter6)
    - 13.1 方法梯度，硬性关注
    - 13.2 Q - 学习，评价器
    - 参考文献
  - 第 14 章 [视频理解](https://charmve.github.io/computer-vision-in-action/#/chapter1/chapter1)
    - 14.1 概述
    - 14.2 行为理解
    - 14.3 主流方法
    - 参考文献
  - 第 15 章 [迁移学习]()
  - 第 16 章 [注意力机制 Attention is All You Need](./notebooks/14_Attention.ipynb)
    - 16.1 Attention with RNNs
    - 16.2 通用注意力
      - 16.2.1 Self-attention 自注意力
      - 16.2.2 Positional encoding
      - 16.2.3 Masked attention
      - 16.2.4 Multi-head attention
    - 参考文献
  - 第 17 章 [跨界模型 Transformer](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md)
    - 17.1 [思想和框图](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#%E4%B8%80%E6%80%9D%E6%83%B3%E5%92%8C%E6%A1%86%E5%9B%BE)
    - 17.2 [实现细节](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#二实现细节)
      - [2.1 Encoder](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#2-1-Encoder)
      - [2.2 Decoder](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#2-2-Decoder)
      - [2.3 Self-Attention](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#2-3-Self-Attention)
      - [2.4 Multi-Headed Attention](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#2-4-Multi-Headed-Attention)
      - [2.5 Positional Encoding](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#2-5-Positional-Encoding)
    - 17.3 [应用任务和结果](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#三-应用任务和结果)
      - [3.1 NLP领域](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#3-1-NLP领域)
      - [3.2 CV领域](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#3-2-CV领域)
        - [3.2.1 检测DETR](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#3-2-1-检测DETR)
        - [3.2.2 分类ViT](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#3-2-2-分类ViT)
        - [3.2.3 分割SETR](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#3-2-3-分割SETR)
        - [3.2.4 Deformable-DETR](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#3-2-4-Deformable-DETR)
    - 17.4 [优点及分析](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#四-优点及分析)
    - 17.5 [缺点及分析](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#五-缺点及分析)
    - [参考文献](https://github.com/Charmve/computer-vision-in-action/blob/main/docs/3_%E8%BF%9B%E9%98%B6%E7%AF%87/chapter7-%E8%B7%A8%E7%95%8C%E6%A8%A1%E5%9E%8B%20Transformer/chapter7_Transformer.md#六-参考文献)
  - 第 18 章 [知识蒸馏]()
    - 18.1 概述
    - [参考文献](#六-参考文献)
  - 第 19 章 [Normalization 模型]()
    - 19.1 概述
    - [参考文献](#六-参考文献)
    
  - <b><h4>附录</h4></b>
    - A 矩阵
    - B 梯度下降法
    - C 模型压缩与裁剪
  - <b><h4>后记</h4></b>
  - <b><h4>参考文献</h4></b>

<br>
- <b>更新中 ...</b>

</tr>
</td>
</table>

## 致谢
<a href="https://maiweiai.github.io/"><img src="https://github.com/Charmve/computer-vision-in-action/blob/main/res/maiwei_ai.png" height="36" alt="迈微AI研习社" title="迈微AI研习社"> </a> <a href="https://madewithml.com/"><img src="https://madewithml.com/static/images/logo.png" height="30" alt="Made With ML" title="Made With ML"> </a> &nbsp;&nbsp; <a href="https://www.epubit.com/"><img src="https://cdn.ptpress.cn/pubcloud/3/app/0718A6B0/cover/20191204BD54009A.png" height="30" alt="异步社区" title="异步社区"> </a>  &nbsp;&nbsp; <a href="https://360.cn"><img src="https://p3.ssl.qhimg.com/t011e94f0b9ed8e66b0.png" height="36" alt="奇虎360" title="奇虎360"> </a> 

## 参考文献

--> Go to see [<b>REFERENCE.md</b>](docs/REFERENCE.md), &nbsp; 感谢前人的杰出工作，我才得以写出此书。

## 关注我们
<div align=center>
<p>扫描下方二维码，然后回复关键词“<b>计算机视觉实战教程</b>”，即可加入“读者交流群”</p>
<img src="https://user-images.githubusercontent.com/29084184/116501908-a63da600-a8e4-11eb-827c-7772655e0079.png" width = "250" height = "270" alt="迈微AI研习社是一个专注AI领域的开源组织，作者系CSDN博客专家，主要分享机器学习算法、计算机视觉等相关内容，每周研读顶会论文，持续关注前沿技术动态。底部有菜单分类，关注我们，一起学习成长。">
</div>

- 若本书里没有你想要理论和实战项目，或者你发现本书哪个地方有错误，请毫不犹豫地去我们 GitHub 的 Issues（ 地址 https://github.com/charmve/computer-vision-in-action/issues ）进行反馈，在对应版块提交你希望补充的内容或者勘误信息，我们通常会在 24 小时以内给您回复，超过 24 小时未回复的话可以邮件联系我们（微信 MaiweiE_com）；
- 同时，我也欢迎大家加入本项目的建设中来，欢迎 [pull request](https://github.com/charmve/computer-vision-in-action/pulls)！

## LICENSE
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-lightgrey" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"> 知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a> 进行许可。

## CONTRIBUTION
<table>
<tr>
<td>
<div class="f5 contribution">
  <h3 class="f4">Help us make these docs great!</h3>
  <p class="color-text-secondary f6">All <b><i>VC-action</i></b> docs are open source. See something that's wrong or unclear? <a href="https://github.com/Charmve/computer-vision-in-action/pulls">Submit a pull request</a>.</p>
  <a class="btn btn-outline" href="https://github.com/Charmve/computer-vision-in-action/edit/main/README.md">
    <svg version="1.1" width="16" height="16" viewBox="0 0 16 16" class="octicon octicon-git-pull-request" aria-hidden="true"><path fill-rule="evenodd" d="M7.177 3.073L9.573.677A.25.25 0 0110 .854v4.792a.25.25 0 01-.427.177L7.177 3.427a.25.25 0 010-.354zM3.75 2.5a.75.75 0 100 1.5.75.75 0 000-1.5zm-2.25.75a2.25 2.25 0 113 2.122v5.256a2.251 2.251 0 11-1.5 0V5.372A2.25 2.25 0 011.5 3.25zM11 2.5h-1V4h1a1 1 0 011 1v5.628a2.251 2.251 0 101.5 0V5A2.5 2.5 0 0011 2.5zm1 10.25a.75.75 0 111.5 0 .75.75 0 01-1.5 0zM3.75 12a.75.75 0 100 1.5.75.75 0 000-1.5z"></path></svg>
    Make a contribution
  </a></div>
  <br><p class="color-text-secondary f6 mt-2">Or, <a href="https://github.com/Charmve/computer-vision-in-action/blob/main/CONTRIBUTING.md" target="_blank">learn how to contribute.</a></p>


<div>
  <h3 class="mb-2 f4">
    Still need help?
  </h3>
  <a id="ask-community" href="https://github.com/Charmve/computer-vision-in-action/discussions" class="btn btn-outline mr-4 mt-2">
    <svg version="1.1" width="16" height="16" viewBox="0 0 16 16" class="octicon octicon-people" aria-hidden="true"><path fill-rule="evenodd" d="M5.5 3.5a2 2 0 100 4 2 2 0 000-4zM2 5.5a3.5 3.5 0 115.898 2.549 5.507 5.507 0 013.034 4.084.75.75 0 11-1.482.235 4.001 4.001 0 00-7.9 0 .75.75 0 01-1.482-.236A5.507 5.507 0 013.102 8.05 3.49 3.49 0 012 5.5zM11 4a.75.75 0 100 1.5 1.5 1.5 0 01.666 2.844.75.75 0 00-.416.672v.352a.75.75 0 00.574.73c1.2.289 2.162 1.2 2.522 2.372a.75.75 0 101.434-.44 5.01 5.01 0 00-2.56-3.012A3 3 0 0011 4z"></path></svg>
    Ask our community
  </a>
  <a id="contact-us" href="https://github.com/Charmve" class="btn btn-outline mt-2">
    <svg version="1.1" width="16" height="16" viewBox="0 0 16 16" class="octicon octicon-comment-discussion" aria-hidden="true"><path fill-rule="evenodd" d="M1.5 2.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v5.5a.25.25 0 01-.25.25h-3.5a.75.75 0 00-.53.22L3.5 11.44V9.25a.75.75 0 00-.75-.75h-1a.25.25 0 01-.25-.25v-5.5zM1.75 1A1.75 1.75 0 000 2.75v5.5C0 9.216.784 10 1.75 10H2v1.543a1.457 1.457 0 002.487 1.03L7.061 10h3.189A1.75 1.75 0 0012 8.25v-5.5A1.75 1.75 0 0010.25 1h-8.5zM14.5 4.75a.25.25 0 00-.25-.25h-.5a.75.75 0 110-1.5h.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0114.25 12H14v1.543a1.457 1.457 0 01-2.487 1.03L9.22 12.28a.75.75 0 111.06-1.06l2.22 2.22v-2.19a.75.75 0 01.75-.75h1a.25.25 0 00.25-.25v-5.5z"></path></svg>
    Contact support
  </a>
</div>
<br>
</td>
</tr>
<table>

## Stargazers Over Time

[![Stargazers over time](https://starchart.cc/Charmve/computer-vision-in-action.svg)](https://starchart.cc/Charmve/computer-vision-in-action)

<br>
<p align="center">Feel free to ask any questions, open a PR if you feel something can be done differently!</p>
<h2 align="center">🌟Star this repository🌟</h2>
<p align="center">Created by <a href="https://github.com/Charmve">Charmve</a> & <a href="https://github.com/MaiweiAI">maiwei.ai</a> Community | Deployed on <a href="https://app.gitbook.com/@charmve/s/computer-vision-in-action/">GitBook</a></p>

<br>
* <i>Update on Apr 29，2021 @<a href="https://github.com/Charmve" target="_blank">Charmve</a>, 
    <a class="github-button"
        href="https://github.com/Charmve/Surface-Defect-Detection"
        data-icon="octicon-star" data-show-count="true"
        aria-label="Star Charmve/Surface-Defect-Detection on GitHub">Star</a> 
    and 
    <a class="github-button"
        href="https://github.com/Charmve/Surface-Defect-Detection/fork"
        data-icon="octicon-repo-forked" data-show-count="true"
        aria-label="Fork Charmve/Surface-Defect-Detection on GitHub">Fork</a>
</i>
